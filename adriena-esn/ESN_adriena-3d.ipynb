{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(object):\n",
    "    \"\"\"\n",
    "    Build a reservoir and evaluate internal states\n",
    "    \n",
    "    Parameters:\n",
    "        n_internal_units = processing units in the reservoir\n",
    "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
    "        leak = amount of leakage in the reservoir state update (optional)\n",
    "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
    "        input_scaling = scaling of the input connection weights\n",
    "        noise_level = deviation of the Gaussian noise injected in the state update\n",
    "        circle = generate determinisitc reservoir with circle topology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
    "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self._n_internal_units = n_internal_units\n",
    "        self._input_scaling = input_scaling\n",
    "        self._noise_level = noise_level\n",
    "        self._leak = leak\n",
    "\n",
    "        # Input weights depend on input size: they are set when data is provided\n",
    "        self._input_weights = None\n",
    "\n",
    "        # Generate internal weights\n",
    "        if circle:\n",
    "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
    "                    n_internal_units,\n",
    "                    spectral_radius)\n",
    "        else:\n",
    "            self._internal_weights = self._initialize_internal_weights(\n",
    "                n_internal_units,\n",
    "                connectivity,\n",
    "                spectral_radius)\n",
    "\n",
    "\n",
    "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
    "        \n",
    "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
    "        internal_weights[0,-1] = spectral_radius\n",
    "        for i in range(n_internal_units-1):\n",
    "            internal_weights[i+1,i] = spectral_radius\n",
    "                \n",
    "        return internal_weights\n",
    "    \n",
    "    \n",
    "    def _initialize_internal_weights(self, n_internal_units,\n",
    "                                     connectivity, spectral_radius):\n",
    "\n",
    "        # Generate sparse, uniformly distributed weights.\n",
    "        internal_weights = sparse.rand(n_internal_units,\n",
    "                                       n_internal_units,\n",
    "                                       density=connectivity).todense()\n",
    "\n",
    "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
    "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
    "        \n",
    "        # Adjust the spectral radius.\n",
    "        E, _ = np.linalg.eig(internal_weights)\n",
    "        e_max = np.max(np.abs(E))\n",
    "        internal_weights /= np.abs(e_max)/spectral_radius       \n",
    "\n",
    "        return internal_weights\n",
    "\n",
    "\n",
    "    def _compute_state_matrix(self, X, n_drop=0):\n",
    "        N, T, _ = X.shape\n",
    "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
    "\n",
    "        # Storage\n",
    "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
    "        for t in range(T):\n",
    "            current_input = X[:, t, :]\n",
    "\n",
    "            # Calculate state\n",
    "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
    "\n",
    "            # Add noise\n",
    "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
    "\n",
    "            # Apply nonlinearity and leakage (optional)\n",
    "            if self._leak is None:\n",
    "                previous_state = np.tanh(state_before_tanh).T\n",
    "            else:\n",
    "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
    "\n",
    "            # Store everything after the dropout period\n",
    "            if (t > n_drop - 1):\n",
    "                state_matrix[:, t - n_drop, :] = previous_state\n",
    "\n",
    "        return state_matrix\n",
    "\n",
    "\n",
    "    def get_states(self, X, n_drop=0, bidir=True):\n",
    "        N, T, V = X.shape\n",
    "        if self._input_weights is None:\n",
    "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
    "\n",
    "        # compute sequence of reservoir states\n",
    "        states = self._compute_state_matrix(X, n_drop)\n",
    "    \n",
    "        # reservoir states on time reversed input\n",
    "        if bidir is True:\n",
    "            X_r = X[:, ::-1, :]\n",
    "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
    "            states = np.concatenate((states, states_r), axis=2)\n",
    "\n",
    "        return states\n",
    "    \n",
    "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False):\n",
    "\n",
    "        res_states = self.get_states(X, n_drop=5, bidir=True)\n",
    "\n",
    "\n",
    "        N_samples = res_states.shape[0]\n",
    "        res_states = res_states.reshape(-1, res_states.shape[2])                   \n",
    "        # ..transform..\n",
    "        if test:\n",
    "            red_states = pca.transform(res_states)\n",
    "        else:\n",
    "            red_states = pca.fit_transform(res_states)          \n",
    "        # ..and put back in tensor form\n",
    "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])  \n",
    "\n",
    "        coeff_tr = []\n",
    "        biases_tr = []   \n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
    "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
    "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
    "        #print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
    "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
    "        return input_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetify(s):\n",
    "    if s == 'Benign':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqArray(a,b):\n",
    "    return np.where(a == b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\", \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\"]\n",
    "\n",
    "features_Th15022018 = ['Fwd Seg Size Min', 'Init Fwd Win Byts', 'Bwd Pkt Len Max', 'Fwd IAT Min', 'Bwd IAT Mean', 'Fwd IAT Tot', 'Flow IAT Mean', 'Flow Duration', 'Fwd IAT Mean', 'Pkt Len Max', \n",
    "                       'Fwd IAT Max', 'Bwd Pkt Len Std', 'PSH Flag Cnt', 'Flow IAT Min', 'Bwd IAT Max', 'ACK Flag Cnt', 'Flow IAT Max', 'Idle Max', 'Fwd Header Len', 'Flow IAT Std']\n",
    "features_Fr16022018 = ['Fwd Pkt Len Std', 'Pkt Len Std', 'Fwd Seg Size Avg', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Max', 'TotLen Fwd Pkts', 'Pkt Len Var', 'Bwd Pkt Len Max', 'Pkt Len Max', 'Pkt Size Avg',\n",
    "                       'Bwd Seg Size Avg', 'Flow IAT Std', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Fwd IAT Max', 'PSH Flag Cnt', 'ACK Flag Cnt', 'Fwd IAT Std', 'Subflow Fwd Byts', 'Flow IAT Mean']\n",
    "\n",
    "#numFeatures = [5, 10, 15, 20]\n",
    "#fracOfData = [0.5, 0.75, 1]\n",
    "numInternalUnits = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "path = \"../Datasets/Raw_Dataset/\" + dataset\n",
    "df = pd.read_csv(path)\n",
    "num_features = 15 # should be 10, 15, or 20\n",
    "features = features_Th15022018[0:num_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 features\n",
      "fraction:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading X and y......\n",
      "X_train shape:(786431, 15, 1) y_train shape:(786431,)\n",
      "X_test shape:(262144, 15, 1) y_test shape:(262144,)\n"
     ]
    }
   ],
   "source": [
    "fraction = 1\n",
    "print(str(num_features) + \" features\")\n",
    "print(\"fraction:\" + str(fraction))\n",
    "data = df.sample(frac=fraction, replace=True, random_state=1)\n",
    "\n",
    "# get X and y. Normalize X and make it into 3D shape for reservoir\n",
    "num_col = data.shape[1]\n",
    "num_row = data.shape[0]\n",
    "\n",
    "X_data = data[features]\n",
    "X_data[features] = X_data[features].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_data.values)\n",
    "X = np.nan_to_num(x_scaled)\n",
    "if len(X.shape) < 3:\n",
    "    X = np.atleast_3d(X)\n",
    "y = data['Label'].apply(targetify)\n",
    "print(\"Finished loading X and y......\")\n",
    "\n",
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print(\"X_train shape:\" + str(X_train.shape), \"y_train shape:\" + str(y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape), \"y_test shape:\" + str(y_test.shape))\n",
    "\n",
    "pca = PCA() #n_components gives number of components to keep for linear dimensionality reduction\n",
    "ridge_embedding = Ridge(alpha=10, fit_intercept=True)\n",
    "readout = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 internal units\n"
     ]
    }
   ],
   "source": [
    "for n in numInternalUnits:\n",
    "    print(str(n) + \" internal units\")\n",
    "\n",
    "    #run through reservoir\n",
    "    res = Reservoir(n_internal_units=n, spectral_radius=0.6, leak=0.6,\n",
    "         connectivity=0.25, input_scaling=0.1, noise_level=0.01, circle=False)\n",
    "    input_repr = res.getReservoirEmbedding(np.array(X_train), pca, ridge_embedding,  n_drop=5, bidir=False, test = False)\n",
    "    print(\"Finished loading training reservoir embedding......\")\n",
    "    input_repr_te = res.getReservoirEmbedding(np.array(X_test), pca, ridge_embedding,  n_drop=5, bidir=False, test = True)\n",
    "    print(\"Finished loading testing reservoir embedding......\")\n",
    "\n",
    "    #fit output\n",
    "    readout.fit(input_repr, y_train)\n",
    "    pred_class = readout.predict(input_repr_te)\n",
    "    predictions = [int(round(x)) for x in pred_class]\n",
    "    true_class = list(y_test)\n",
    "\n",
    "    #analysis\n",
    "    compdf = pd.DataFrame({'pred_class':pred_class, 'true_class':true_class})\n",
    "    compdf = compdf.sort_values('pred_class', ascending=False)\n",
    "    print(str(compdf.head(10)))\n",
    "    compdf.to_csv(str(dataset.split('_')[0]) + '_' + str(fraction) + '_' + str(num_features) + '_' + str(n) + '.csv')\n",
    "    accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "    f1 = f1_score(true_class, predictions)\n",
    "    auc = roc_auc_score(true_class, predictions)\n",
    "\n",
    "    print(\"# of nonzero:\" + str(np.count_nonzero(predictions)))\n",
    "    print(\"accuracy is \" + str(accuracy))\n",
    "    print(\"f1 is \" + str(f1))\n",
    "    print(\"auc is \" + str(auc))\n",
    "    print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/Raw_0.5_10_5.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
