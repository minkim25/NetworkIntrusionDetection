{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(object):\n",
    "    \"\"\"\n",
    "    Build a reservoir and evaluate internal states\n",
    "    \n",
    "    Parameters:\n",
    "        n_internal_units = processing units in the reservoir\n",
    "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
    "        leak = amount of leakage in the reservoir state update (optional)\n",
    "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
    "        input_scaling = scaling of the input connection weights\n",
    "        noise_level = deviation of the Gaussian noise injected in the state update\n",
    "        circle = generate determinisitc reservoir with circle topology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
    "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self._n_internal_units = n_internal_units\n",
    "        self._input_scaling = input_scaling\n",
    "        self._noise_level = noise_level\n",
    "        self._leak = leak\n",
    "\n",
    "        # Input weights depend on input size: they are set when data is provided\n",
    "        self._input_weights = None\n",
    "\n",
    "        # Generate internal weights\n",
    "        if circle:\n",
    "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
    "                    n_internal_units,\n",
    "                    spectral_radius)\n",
    "        else:\n",
    "            self._internal_weights = self._initialize_internal_weights(\n",
    "                n_internal_units,\n",
    "                connectivity,\n",
    "                spectral_radius)\n",
    "\n",
    "\n",
    "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
    "        \n",
    "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
    "        internal_weights[0,-1] = spectral_radius\n",
    "        for i in range(n_internal_units-1):\n",
    "            internal_weights[i+1,i] = spectral_radius\n",
    "                \n",
    "        return internal_weights\n",
    "    \n",
    "    \n",
    "    def _initialize_internal_weights(self, n_internal_units,\n",
    "                                     connectivity, spectral_radius):\n",
    "\n",
    "        # Generate sparse, uniformly distributed weights.\n",
    "        internal_weights = sparse.rand(n_internal_units,\n",
    "                                       n_internal_units,\n",
    "                                       density=connectivity).todense()\n",
    "\n",
    "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
    "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
    "        \n",
    "        # Adjust the spectral radius.\n",
    "        E, _ = np.linalg.eig(internal_weights)\n",
    "        e_max = np.max(np.abs(E))\n",
    "        internal_weights /= np.abs(e_max)/spectral_radius       \n",
    "\n",
    "        return internal_weights\n",
    "\n",
    "\n",
    "    def _compute_state_matrix(self, X, n_drop=0):\n",
    "        N, T, _ = X.shape\n",
    "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
    "\n",
    "        # Storage\n",
    "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
    "        for t in range(T):\n",
    "            current_input = X[:, t, :]\n",
    "\n",
    "            # Calculate state\n",
    "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
    "\n",
    "            # Add noise\n",
    "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
    "\n",
    "            # Apply nonlinearity and leakage (optional)\n",
    "            if self._leak is None:\n",
    "                previous_state = np.tanh(state_before_tanh).T\n",
    "            else:\n",
    "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
    "\n",
    "            # Store everything after the dropout period\n",
    "            if (t > n_drop - 1):\n",
    "                state_matrix[:, t - n_drop, :] = previous_state\n",
    "\n",
    "        return state_matrix\n",
    "\n",
    "\n",
    "    def get_states(self, X, n_drop=0, bidir=True):\n",
    "        N, T, V = X.shape\n",
    "        if self._input_weights is None:\n",
    "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
    "\n",
    "        # compute sequence of reservoir states\n",
    "        states = self._compute_state_matrix(X, n_drop)\n",
    "    \n",
    "        # reservoir states on time reversed input\n",
    "        if bidir is True:\n",
    "            X_r = X[:, ::-1, :]\n",
    "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
    "            states = np.concatenate((states, states_r), axis=2)\n",
    "\n",
    "        return states\n",
    "    \n",
    "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False):\n",
    "\n",
    "        res_states = self.get_states(X, n_drop=5, bidir=True)\n",
    "\n",
    "\n",
    "        N_samples = res_states.shape[0]\n",
    "        res_states = res_states.reshape(-1, res_states.shape[2])                   \n",
    "        # ..transform..\n",
    "        if test:\n",
    "            red_states = pca.transform(res_states)\n",
    "        else:\n",
    "            red_states = pca.fit_transform(res_states)          \n",
    "        # ..and put back in tensor form\n",
    "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])  \n",
    "\n",
    "        coeff_tr = []\n",
    "        biases_tr = []   \n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
    "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
    "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
    "        #print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
    "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
    "        return input_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetify(s):\n",
    "    if s == 'Benign':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqArray(a,b):\n",
    "    return np.where(a == b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\", \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\"]\n",
    "\n",
    "features_Th15022018 = ['Fwd Seg Size Min', 'Init Fwd Win Byts', 'Bwd Pkt Len Max', 'Fwd IAT Min', 'Bwd IAT Mean', 'Fwd IAT Tot', 'Flow IAT Mean', 'Flow Duration', 'Fwd IAT Mean', 'Pkt Len Max', \n",
    "                       'Fwd IAT Max', 'Bwd Pkt Len Std', 'PSH Flag Cnt', 'Flow IAT Min', 'Bwd IAT Max', 'ACK Flag Cnt', 'Flow IAT Max', 'Idle Max', 'Fwd Header Len', 'Flow IAT Std']\n",
    "features_Fr16022018 = ['Fwd Pkt Len Std', 'Pkt Len Std', 'Fwd Seg Size Avg', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Max', 'TotLen Fwd Pkts', 'Pkt Len Var', 'Bwd Pkt Len Max', 'Pkt Len Max', 'Pkt Size Avg',\n",
    "                       'Bwd Seg Size Avg', 'Flow IAT Std', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Fwd IAT Max', 'PSH Flag Cnt', 'ACK Flag Cnt', 'Fwd IAT Std', 'Subflow Fwd Byts', 'Flow IAT Mean']\n",
    "\n",
    "#numFeatures = [10, 15, 20]\n",
    "#fracOfData = [0.5, 0.75, 1]\n",
    "#numInternalUnits = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "path = \"../Datasets/Raw_Dataset/\" + dataset\n",
    "df = pd.read_csv(path)\n",
    "num_features = 10\n",
    "features = features_Fr16022018[0:num_features]\n",
    "fraction = 0.75\n",
    "n=5 #number of internal units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features\n",
      "fraction:0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading X and y......\n",
      "X_train shape:(589823, 10, 1) y_train shape:(589823,)\n",
      "X_test shape:(196608, 10, 1) y_test shape:(196608,)\n"
     ]
    }
   ],
   "source": [
    "print(str(num_features) + \" features\")\n",
    "print(\"fraction:\" + str(fraction))\n",
    "data = df.sample(frac=fraction, replace=True, random_state=1)\n",
    "\n",
    "# get X and y. Normalize X and make it into 3D shape for reservoir\n",
    "num_col = data.shape[1]\n",
    "num_row = data.shape[0]\n",
    "\n",
    "X_data = data[features]\n",
    "X_data[features] = X_data[features].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_data.values)\n",
    "X = np.nan_to_num(x_scaled)\n",
    "if len(X.shape) < 3:\n",
    "    X = np.atleast_3d(X)\n",
    "y = data['Label'].apply(targetify)\n",
    "print(\"Finished loading X and y......\")\n",
    "\n",
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print(\"X_train shape:\" + str(X_train.shape), \"y_train shape:\" + str(y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape), \"y_test shape:\" + str(y_test.shape))\n",
    "\n",
    "pca = PCA() #n_components gives number of components to keep for linear dimensionality reduction\n",
    "ridge_embedding = Ridge(alpha=10, fit_intercept=True)\n",
    "readout = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 internal units\n",
      "input_scaling: 0.3\n",
      "spectral_radius: 0.9\n",
      "leaking rate: 0.2\n",
      "Finished loading training reservoir embedding......\n",
      "Finished loading testing reservoir embedding......\n",
      "        pred_class  true_class\n",
      "180463    1.223153           1\n",
      "17673     1.198138           1\n",
      "149165    1.196657           1\n",
      "142340    1.195524           1\n",
      "126047    1.194874           1\n",
      "163117    1.193774           1\n",
      "26547     1.193599           1\n",
      "147536    1.192770           1\n",
      "156163    1.188533           1\n",
      "152437    1.185966           1\n",
      "# of nonzero:114099\n",
      "accuracy is 0.9958394368489584\n",
      "*******************************************************************\n",
      "input_scaling: 0.3\n",
      "spectral_radius: 0.9\n",
      "leaking rate: 0.6\n",
      "Finished loading training reservoir embedding......\n",
      "Finished loading testing reservoir embedding......\n",
      "        pred_class  true_class\n",
      "179655    2.119526           0\n",
      "61894     1.116945           1\n",
      "137979    1.105840           1\n",
      "147647    1.102921           1\n",
      "195552    1.099403           1\n",
      "87694     1.094010           1\n",
      "136790    1.093679           1\n",
      "108189    1.092396           1\n",
      "123920    1.091752           1\n",
      "120182    1.090361           1\n",
      "# of nonzero:114082\n",
      "accuracy is 0.9958953857421875\n",
      "*******************************************************************\n",
      "input_scaling: 0.3\n",
      "spectral_radius: 0.9\n",
      "leaking rate: 0.9\n",
      "Finished loading training reservoir embedding......\n",
      "Finished loading testing reservoir embedding......\n",
      "        pred_class  true_class\n",
      "179655    4.909458           0\n",
      "100046    1.153831           0\n",
      "149866    1.102940           1\n",
      "30751     1.100065           1\n",
      "106426    1.097291           1\n",
      "161795    1.090833           1\n",
      "91282     1.089519           1\n",
      "175874    1.085946           1\n",
      "187230    1.084293           1\n",
      "90210     1.083898           1\n",
      "# of nonzero:114082\n",
      "accuracy is 0.9957021077473959\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(str(n) + \" internal units\")\n",
    "for input_scaling in [0.3]:\n",
    "    for spectral_radius in [0.9]:\n",
    "        for leaking_rate in [0.2, 0.6, 0.9]:\n",
    "            print(\"input_scaling: \" + str(input_scaling))\n",
    "            print(\"spectral_radius: \" + str(spectral_radius))\n",
    "            print(\"leaking rate: \" + str(leaking_rate))\n",
    "            \n",
    "            #run through reservoir\n",
    "            res = Reservoir(n_internal_units=n, spectral_radius=spectral_radius, leak=leaking_rate,\n",
    "                 connectivity=0.25, input_scaling=input_scaling, noise_level=0.01, circle=False)\n",
    "            input_repr = res.getReservoirEmbedding(np.array(X_train), pca, ridge_embedding,  n_drop=5, bidir=False, test = False)\n",
    "            print(\"Finished loading training reservoir embedding......\")\n",
    "            input_repr_te = res.getReservoirEmbedding(np.array(X_test), pca, ridge_embedding,  n_drop=5, bidir=False, test = True)\n",
    "            print(\"Finished loading testing reservoir embedding......\")\n",
    "\n",
    "            #fit output\n",
    "            readout.fit(input_repr, y_train)\n",
    "            pred_class = readout.predict(input_repr_te)\n",
    "            predictions = [int(round(x)) for x in pred_class]\n",
    "            true_class = list(y_test)\n",
    "\n",
    "            #analysis\n",
    "            compdf = pd.DataFrame({'pred_class':pred_class, 'true_class':true_class})\n",
    "            compdf = compdf.sort_values('pred_class', ascending=False)\n",
    "            print(str(compdf.head(10)))\n",
    "            compdf.to_csv(str(dataset.split('_')[0]) + 'parameters_' + str(input_scaling) + '_' + str(spectral_radius) + '_' + str(leaking_rate) + '.csv')\n",
    "            accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "            #f1 = f1_score(true_class, predictions)\n",
    "            #auc = roc_auc_score(true_class, predictions)\n",
    "\n",
    "            print(\"# of nonzero:\" + str(np.count_nonzero(predictions)))\n",
    "            print(\"accuracy is \" + str(accuracy))\n",
    "            #print(\"f1 is \" + str(f1))\n",
    "            #print(\"auc is \" + str(auc))\n",
    "            print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hulk Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.0.12-23.59.158.215-63949-443-6</td>\n",
       "      <td>23.59.158.215</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>63949</td>\n",
       "      <td>6</td>\n",
       "      <td>6/12/2019 9:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.0.12-192.168.0.15-0-0-0</td>\n",
       "      <td>192.168.0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2019 9:19</td>\n",
       "      <td>119471947</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ModifiedHuLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0.6.4-8.6.0.1-0-0-0</td>\n",
       "      <td>8.6.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0.6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2019 9:19</td>\n",
       "      <td>115023918</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.249888e+06</td>\n",
       "      <td>6.028923e+06</td>\n",
       "      <td>15500000.0</td>\n",
       "      <td>126</td>\n",
       "      <td>6.886507e+06</td>\n",
       "      <td>3.949426e+06</td>\n",
       "      <td>19000000.0</td>\n",
       "      <td>5000053.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.0.1-239.255.255.250-51772-1900-17</td>\n",
       "      <td>192.168.0.1</td>\n",
       "      <td>51772</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>6/12/2019 9:20</td>\n",
       "      <td>106023344</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.730851e+05</td>\n",
       "      <td>4.610152e+03</td>\n",
       "      <td>278251.0</td>\n",
       "      <td>266549</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>4.878160e+05</td>\n",
       "      <td>15700000.0</td>\n",
       "      <td>14100000.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239.255.255.250-20.20.20.1-1900-33157-17</td>\n",
       "      <td>20.20.20.1</td>\n",
       "      <td>33157</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>6/12/2019 9:20</td>\n",
       "      <td>106014555</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.647474e+05</td>\n",
       "      <td>4.230452e+03</td>\n",
       "      <td>270305.0</td>\n",
       "      <td>258567</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>4.878088e+05</td>\n",
       "      <td>15800000.0</td>\n",
       "      <td>14100000.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Flow ID         Src IP  Src Port  \\\n",
       "0     192.168.0.12-23.59.158.215-63949-443-6  23.59.158.215       443   \n",
       "1            192.168.0.12-192.168.0.15-0-0-0   192.168.0.15         0   \n",
       "2                      8.0.6.4-8.6.0.1-0-0-0        8.6.0.1         0   \n",
       "3  192.168.0.1-239.255.255.250-51772-1900-17    192.168.0.1     51772   \n",
       "4   239.255.255.250-20.20.20.1-1900-33157-17     20.20.20.1     33157   \n",
       "\n",
       "            Dst IP  Dst Port  Protocol       Timestamp  Flow Duration  \\\n",
       "0     192.168.0.12     63949         6  6/12/2019 9:20              1   \n",
       "1     192.168.0.12         0         0  6/12/2019 9:19      119471947   \n",
       "2          8.0.6.4         0         0  6/12/2019 9:19      115023918   \n",
       "3  239.255.255.250      1900        17  6/12/2019 9:20      106023344   \n",
       "4  239.255.255.250      1900        17  6/12/2019 9:20      106014555   \n",
       "\n",
       "   Tot Fwd Pkts  Tot Bwd Pkts  ...  Fwd Seg Size Min   Active Mean  \\\n",
       "0             1             1  ...                 0  0.000000e+00   \n",
       "1           119             1  ...                 0  0.000000e+00   \n",
       "2            23             1  ...                 0  4.249888e+06   \n",
       "3           351             1  ...                 0  2.730851e+05   \n",
       "4           351             1  ...                 0  2.647474e+05   \n",
       "\n",
       "     Active Std  Active Max  Active Min     Idle Mean      Idle Std  \\\n",
       "0  0.000000e+00         0.0           0  0.000000e+00  0.000000e+00   \n",
       "1  0.000000e+00         0.0           0  0.000000e+00  0.000000e+00   \n",
       "2  6.028923e+06  15500000.0         126  6.886507e+06  3.949426e+06   \n",
       "3  4.610152e+03    278251.0      266549  1.480000e+07  4.878160e+05   \n",
       "4  4.230452e+03    270305.0      258567  1.480000e+07  4.878088e+05   \n",
       "\n",
       "     Idle Max    Idle Min         Label  \n",
       "0         0.0         0.0        Benign  \n",
       "1         0.0         0.0  ModifiedHuLK  \n",
       "2  19000000.0   5000053.0        Benign  \n",
       "3  15700000.0  14100000.0        Benign  \n",
       "4  15800000.0  14100000.0        Benign  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hulkdf = pd.read_csv(\"../CustomDatasets/RegularHulkAttack.csv\")\n",
    "hulkdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Flow Duration', 'Tot Fwd Pkts',\n",
    "       'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
    "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
    "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
    "       'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
    "       'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
    "       'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "       'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
    "       'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
    "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
    "       'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
    "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
    "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
    "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
    "       'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "       'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
    "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_hulk_data = hulkdf[features]\n",
    "X_hulk_data[features] = X_hulk_data[features].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_hulk_scaled = min_max_scaler.fit_transform(X_hulk_data.values)\n",
    "X_hulk = np.nan_to_num(x_hulk_scaled)\n",
    "if len(X_hulk.shape) < 3:\n",
    "    X_hulk = np.atleast_3d(X_hulk)\n",
    "y_hulk = hulkdf['Label'].apply(targetify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading testing reservoir embedding......\n"
     ]
    }
   ],
   "source": [
    "input_repr_te_hulk = res.getReservoirEmbedding(np.array(X_hulk), pca, ridge_embedding,  n_drop=5, bidir=False, test = True)\n",
    "print(\"Finished loading testing reservoir embedding......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_hulk = readout.predict(input_repr_te_hulk)\n",
    "predictions_hulk = [int(round(x)) for x in pred_class_hulk]\n",
    "true_class_hulk = list(y_hulk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compdf_hulk = pd.DataFrame({'pred_class':pred_class_hulk, 'true_class':true_class_hulk})\n",
    "compdf_hulk = compdf_hulk.sort_values('pred_class', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRound(x, r):\n",
    "    if x>r/float(1000):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqArray(a,b):\n",
    "    return np.where(a == b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723242994947175"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_hulk = list(compdf_hulk['pred_class'].apply(myRound, r=225))\n",
    "true_class_hulk = list(compdf_hulk['true_class'])\n",
    "accuracy_hulk = np.sum(list(map(eqArray, predictions_hulk, true_class_hulk))) / len(true_class_hulk)\n",
    "accuracy_hulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  17,  241],\n",
       "       [   0, 8450]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm = confusion_matrix(true_class_hulk, predictions_hulk)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723242994947175"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confm.ravel()\n",
    "(tn + tp)/(tn+tp+fn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
